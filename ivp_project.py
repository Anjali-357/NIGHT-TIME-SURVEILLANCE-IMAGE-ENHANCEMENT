# -*- coding: utf-8 -*-
"""IVP Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OgY3nQBIAy8XbvwvZsCB7WHR9_QCyZEi

## **Night Time Surveillance Image Enhancement**

Step 1: Install Dependencies & Import Libraries
"""

# Install required packages
!pip install opencv-python matplotlib numpy scikit-image scipy pillow

# Import libraries
import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
from google.colab import files
from google.colab.patches import cv2_imshow
from skimage import exposure, feature
from skimage.metrics import structural_similarity as ssim
import glob
from PIL import Image

print("► Libraries imported successfully!")

"""Step 2: Mount Google Drive & Setup"""

# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Set dataset path
dataset_path = "/content/drive/MyDrive/LoLI_Street_Dataset_extracted"
print(f"► Dataset path: {dataset_path}")

"""Step 3: Dataset Loader"""

def load_loli_dataset_images(num_samples=3):
    """Load images from LoLI-Street dataset"""
    print("► Loading images from LoLI-Street dataset...")

    base_path = "/content/drive/MyDrive/LoLI_Street_Dataset_extracted/LoLI-Street Dataset"

    if not os.path.exists(base_path):
        print(f"► Dataset path not found: {base_path}")
        return [], []

    low_images = []
    high_images = []

    # Try Train directory first
    train_low_path = os.path.join(base_path, "Train", "low")
    train_high_path = os.path.join(base_path, "Train", "high")

    if os.path.exists(train_low_path) and os.path.exists(train_high_path):
        print("► Found Train directory with low/high pairs")

        low_files = []
        for ext in ['*.jpg', '*.jpeg', '*.png']:
            low_files.extend(glob.glob(os.path.join(train_low_path, ext)))

        for low_file in low_files[:num_samples]:
            low_img = cv2.imread(low_file)
            if low_img is None:
                continue

            filename = os.path.basename(low_file)
            high_file = os.path.join(train_high_path, filename)

            if os.path.exists(high_file):
                high_img = cv2.imread(high_file)
                if high_img is not None:
                    if low_img.shape != high_img.shape:
                        high_img = cv2.resize(high_img, (low_img.shape[1], low_img.shape[0]))

                    low_images.append(low_img)
                    high_images.append(high_img)
                    print(f"► Loaded pair: {filename}")

    print(f"► Successfully loaded {len(low_images)} image pairs")
    return low_images, high_images

# Test dataset loading
low_images, high_images = load_loli_dataset_images(2)

"""Step 4: Image Enhancement Techniques"""

class ImageEnhancementTechniques:
    def __init__(self):
        pass

    def histogram_equalization(self, image):
        if len(image.shape) == 3:
            yuv = cv2.cvtColor(image, cv2.COLOR_BGR2YUV)
            yuv[:,:,0] = cv2.equalizeHist(yuv[:,:,0])
            return cv2.cvtColor(yuv, cv2.COLOR_YUV2BGR)
        else:
            return cv2.equalizeHist(image)

    def clahe_enhancement(self, image, clip_limit=2.0, grid_size=(8,8)):
        if len(image.shape) == 3:
            lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
            clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=grid_size)
            lab[:,:,0] = clahe.apply(lab[:,:,0])
            return cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)
        else:
            clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=grid_size)
            return clahe.apply(image)

    def gamma_correction(self, image, gamma=1.5):
        inv_gamma = 1.0 / gamma
        table = np.array([((i / 255.0) ** inv_gamma) * 255 for i in np.arange(0, 256)]).astype("uint8")
        return cv2.LUT(image, table)

    def unsharp_masking(self, image, kernel_size=(5,5), sigma=1.0, amount=1.0):
        blurred = cv2.GaussianBlur(image, kernel_size, sigma)
        sharpened = cv2.addWeighted(image, 1.0 + amount, blurred, -amount, 0)
        return sharpened

    def retinex_enhancement(self, image):
        if len(image.shape) == 3:
            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

        # Single scale retinex for simplicity
        blurred = cv2.GaussianBlur(image.astype(np.float64), (0,0), 80)
        retinex = np.log(image.astype(np.float64) + 1) - np.log(blurred + 1)
        retinex = exposure.rescale_intensity(retinex, out_range=(0,255))
        return retinex.astype(np.uint8)

    def homomorphic_filter(self, image, cutoff=30, high_freq_gain=2.0, low_freq_gain=0.5):
        """Fixed Homomorphic Filter - properly handles color images"""
        if len(image.shape) == 3:
            # Convert to YUV and process only Y (luminance) channel
            yuv = cv2.cvtColor(image, cv2.COLOR_BGR2YUV)
            y_channel = yuv[:,:,0].astype(np.float64)
        else:
            y_channel = image.astype(np.float64)

        # Avoid log(0) by adding small constant
        img_log = np.log(y_channel + 1e-6)

        rows, cols = y_channel.shape
        x, y = np.meshgrid(np.linspace(-0.5, 0.5, cols), np.linspace(-0.5, 0.5, rows))
        radius = np.sqrt(x**2 + y**2)

        # Create homomorphic filter
        filter = (high_freq_gain - low_freq_gain) * (1 - np.exp(-(radius**2) / (2 * (cutoff/max(rows,cols))**2))) + low_freq_gain

        # Apply filter in frequency domain
        img_fft = np.fft.fft2(img_log)
        img_fft_shift = np.fft.fftshift(img_fft)
        filtered_fft = img_fft_shift * filter
        img_fft_ishift = np.fft.ifftshift(filtered_fft)
        img_filtered = np.fft.ifft2(img_fft_ishift)

        # Exponential and rescale
        img_exp = np.exp(np.real(img_filtered))
        img_exp = exposure.rescale_intensity(img_exp, out_range=(0,255))

        if len(image.shape) == 3:
            # Replace Y channel and convert back
            yuv[:,:,0] = img_exp.astype(np.uint8)
            return cv2.cvtColor(yuv, cv2.COLOR_YUV2BGR)
        else:
            return img_exp.astype(np.uint8)

"""Step 5: Enhancement Combinations"""

class EnhancementCombinations:
    def __init__(self):
        self.techniques = ImageEnhancementTechniques()

    def combination_1(self, image):
        """CLAHE + Gamma"""
        enhanced = self.techniques.clahe_enhancement(image)
        enhanced = self.techniques.gamma_correction(enhanced, gamma=1.2)
        return enhanced

    def combination_2(self, image):
        """HistEq + Unsharp"""
        enhanced = self.techniques.histogram_equalization(image)
        enhanced = self.techniques.unsharp_masking(enhanced)
        return enhanced

    def combination_3(self, image):
        """Retinex + CLAHE"""
        enhanced = self.techniques.retinex_enhancement(image)
        if len(image.shape) == 3:
            enhanced = cv2.cvtColor(enhanced, cv2.COLOR_GRAY2BGR)
        enhanced = self.techniques.clahe_enhancement(enhanced)
        return enhanced

    def combination_4(self, image):
        """Homomorphic + Gamma (FIXED)"""
        enhanced = self.techniques.homomorphic_filter(image)
        enhanced = self.techniques.gamma_correction(enhanced, gamma=1.3)
        return enhanced

    def combination_5(self, image):
        """Multi-scale Enhancement"""
        enhanced = self.techniques.clahe_enhancement(image)
        if len(image.shape) == 3:
            gray = cv2.cvtColor(enhanced, cv2.COLOR_BGR2GRAY)
        else:
            gray = enhanced

        # Edge enhancement
        sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)
        sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
        magnitude = np.sqrt(sobelx**2 + sobely**2)
        magnitude = exposure.rescale_intensity(magnitude, out_range=(0,255))

        enhanced_edges = cv2.addWeighted(gray, 0.7, magnitude.astype(np.uint8), 0.3, 0)

        if len(image.shape) == 3:
            enhanced_edges = cv2.cvtColor(enhanced_edges, cv2.COLOR_GRAY2BGR)

        return enhanced_edges

print("► Enhancement combinations defined!")

"""Step 6: Evaluation Metrics"""

def calculate_metrics(original, enhanced, ground_truth=None):
    metrics = {}

    if len(original.shape) == 3:
        original_gray = cv2.cvtColor(original, cv2.COLOR_BGR2GRAY)
        enhanced_gray = cv2.cvtColor(enhanced, cv2.COLOR_BGR2GRAY)
    else:
        original_gray = original
        enhanced_gray = enhanced

    metrics['brightness_improvement'] = np.mean(enhanced_gray) - np.mean(original_gray)
    metrics['contrast_improvement'] = np.std(enhanced_gray) - np.std(original_gray)

    sobel_original = cv2.Sobel(original_gray, cv2.CV_64F, 1, 1, ksize=3)
    sobel_enhanced = cv2.Sobel(enhanced_gray, cv2.CV_64F, 1, 1, ksize=3)
    metrics['edge_preservation'] = np.mean(np.abs(sobel_enhanced)) - np.mean(np.abs(sobel_original))

    if ground_truth is not None:
        if len(ground_truth.shape) == 3:
            ground_truth_gray = cv2.cvtColor(ground_truth, cv2.COLOR_BGR2GRAY)
        else:
            ground_truth_gray = ground_truth
        metrics['ssim'] = ssim(ground_truth_gray, enhanced_gray, data_range=255)

    return metrics

def extract_features(image):
    """Extract SIFT and HOG features"""
    if len(image.shape) == 3:
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    else:
        gray = image

    # SIFT features
    sift = cv2.SIFT_create()
    keypoints, descriptors = sift.detectAndCompute(gray, None)

    # HOG features
    hog_features, hog_image = feature.hog(gray, orientations=9, pixels_per_cell=(8, 8),
                                         cells_per_block=(2, 2), visualize=True, block_norm='L2-Hys')

    return {
        'sift_keypoints': len(keypoints),
        'hog_features': hog_features
    }

"""Step 7: Test All Combinations"""

def test_enhancement_combinations():
    print("► TESTING ENHANCEMENT COMBINATIONS")

    enhancer = EnhancementCombinations()
    techniques = [
        ("CLAHE + Gamma", enhancer.combination_1),
        ("HistEq + Unsharp", enhancer.combination_2),
        ("Retinex + CLAHE", enhancer.combination_3),
        ("Homomorphic + Gamma", enhancer.combination_4),
        ("Multi-scale", enhancer.combination_5),
    ]

    # Load images
    low_images, high_images = load_loli_dataset_images(2)

    if not low_images:
        print("► No images loaded!")
        return "CLAHE + Gamma", enhancer, {}

    results = {}

    # Test on first image
    low_img = low_images[0]
    high_img = high_images[0]

    plt.figure(figsize=(20, 10))

    # Original and Reference
    plt.subplot(2, 4, 1)
    plt.imshow(cv2.cvtColor(low_img, cv2.COLOR_BGR2RGB))
    plt.title("Original\nLow Light", fontweight='bold')
    plt.axis('off')

    plt.subplot(2, 4, 2)
    plt.imshow(cv2.cvtColor(high_img, cv2.COLOR_BGR2RGB))
    plt.title("Reference", fontweight='bold')
    plt.axis('off')

    # Test each technique
    for i, (tech_name, tech_func) in enumerate(techniques):
        try:
            enhanced = tech_func(low_img.copy())
            metrics = calculate_metrics(low_img, enhanced, high_img)
            results[tech_name] = metrics

            # Display enhanced image
            plt.subplot(2, 4, i + 3)
            plt.imshow(cv2.cvtColor(enhanced, cv2.COLOR_BGR2RGB))
            plt.title(f"{tech_name}", fontweight='bold')
            plt.axis('off')

        except Exception as e:
            print(f"► Error in {tech_name}: {e}")
            continue

    plt.tight_layout()
    plt.show()

    # Display metrics
    print("\n► METRICS COMPARISON:")
    print("-" * 80)
    print(f"{'Technique':<20} {'Brightness':<12} {'Contrast':<12} {'Edges':<12} {'SSIM':<12}")
    print("-" * 80)

    best_tech = "CLAHE + Gamma"
    best_score = -float('inf')

    for tech_name, metrics in results.items():
        bright = metrics.get('brightness_improvement', 0)
        contrast = metrics.get('contrast_improvement', 0)
        edges = metrics.get('edge_preservation', 0)
        ssim_val = metrics.get('ssim', 0)

        print(f"{tech_name:<20} {bright:<12.2f} {contrast:<12.2f} {edges:<12.2f} {ssim_val:<12.4f}")

        # Simple scoring: prioritize SSIM and brightness
        score = ssim_val * 0.5 + bright * 0.3 + contrast * 0.2
        if score > best_score:
            best_score = score
            best_tech = tech_name

    print(f"\n► BEST TECHNIQUE: {best_tech}")
    return best_tech, enhancer, results

# Run the test
best_technique, enhancer, results = test_enhancement_combinations()

"""Step 8: Enhanced Image Upload & Processing"""

def enhance_uploaded_image(best_technique_name, enhancer):
    print(f"► USER IMAGE ENHANCEMENT")
    print(f"Using best technique: {best_technique_name}")
    print("Please upload a low-light image...")

    try:
        uploaded = files.upload()

        if not uploaded:
            print("► No file uploaded.")
            return

        for filename in uploaded.keys():
            image = cv2.imdecode(np.frombuffer(uploaded[filename], np.uint8), cv2.IMREAD_COLOR)
            if image is not None:
                print(f"► Uploaded: {filename}")
                break

        if image is None:
            print("► Could not load image.")
            return

        # Apply enhancement
        if best_technique_name == "CLAHE + Gamma":
            enhanced = enhancer.combination_1(image)
        elif best_technique_name == "HistEq + Unsharp":
            enhanced = enhancer.combination_2(image)
        elif best_technique_name == "Retinex + CLAHE":
            enhanced = enhancer.combination_3(image)
        elif best_technique_name == "Homomorphic + Gamma":
            enhanced = enhancer.combination_4(image)
        else:
            enhanced = enhancer.combination_5(image)

        # Calculate metrics and features
        metrics = calculate_metrics(image, enhanced)
        orig_features = extract_features(image)
        enh_features = extract_features(enhanced)

        # Display results
        plt.figure(figsize=(15, 10))

        plt.subplot(2, 3, 1)
        plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
        plt.title("ORIGINAL IMAGE", fontweight='bold')
        plt.axis('off')

        plt.subplot(2, 3, 2)
        plt.imshow(cv2.cvtColor(enhanced, cv2.COLOR_BGR2RGB))
        plt.title(f"ENHANCED\n{best_technique_name}", fontweight='bold')
        plt.axis('off')

        plt.subplot(2, 3, 3)
        comparison = np.hstack([cv2.cvtColor(image, cv2.COLOR_BGR2RGB),
                              cv2.cvtColor(enhanced, cv2.COLOR_BGR2RGB)])
        plt.imshow(comparison)
        plt.title("COMPARISON", fontweight='bold')
        plt.axis('off')

        # Metrics
        plt.subplot(2, 3, 4)
        metric_names = ['Brightness', 'Contrast', 'Edges']
        metric_values = [metrics['brightness_improvement'],
                        metrics['contrast_improvement'],
                        metrics['edge_preservation']]
        colors = ['#1f77b4', '#ff7f0e', '#2ca02c']
        bars = plt.bar(metric_names, metric_values, color=colors)
        plt.title('IMPROVEMENT METRICS', fontweight='bold')
        plt.grid(axis='y', alpha=0.3)

        for bar, value in zip(bars, metric_values):
            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height(),
                    f'{value:.1f}', ha='center', va='bottom', fontweight='bold')

        # Feature comparison
        plt.subplot(2, 3, 5)
        feature_data = [orig_features['sift_keypoints'], enh_features['sift_keypoints']]
        feature_labels = ['Original', 'Enhanced']
        colors = ['#d3d3d3', '#90ee90']
        bars = plt.bar(feature_labels, feature_data, color=colors)
        plt.title('SIFT FEATURES DETECTED', fontweight='bold')
        plt.grid(axis='y', alpha=0.3)

        for bar, value in zip(bars, feature_data):
            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height(),
                    f'{value}', ha='center', va='bottom', fontweight='bold')

        # Summary
        plt.subplot(2, 3, 6)
        plt.axis('off')
        summary_text = f"""
        ENHANCEMENT SUMMARY:

        Technique: {best_technique_name}

        Improvements:
        • Brightness: {metrics['brightness_improvement']:.1f}
        • Contrast: {metrics['contrast_improvement']:.1f}
        • Edge Detail: {metrics['edge_preservation']:.1f}

        Features:
        • SIFT Points: {orig_features['sift_keypoints']} → {enh_features['sift_keypoints']}
        • Improvement: +{enh_features['sift_keypoints'] - orig_features['sift_keypoints']}
        """
        plt.text(0.1, 0.9, summary_text, fontsize=12, fontweight='bold',
                verticalalignment='top', transform=plt.gca().transAxes)

        plt.tight_layout()
        plt.show()

    except Exception as e:
        print(f"► Error: {e}")

# Ready for user upload
print("► READY FOR USER IMAGE ENHANCEMENT")
print("=" * 50)
enhance_uploaded_image(best_technique, enhancer)

"""Step 9: Final Upload Cell to covert th **Low Light Image**  to **Enhanced Image**:"""

print("► UPLOAD YOUR LOW-LIGHT IMAGE")
print("=" * 40)
print("Click 'Choose Files' below to upload your image...")
enhance_uploaded_image(best_technique, enhancer)